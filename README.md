# ai-interviewer

The application flow is like this

## USER FLOW

```bash
USER INPUT
â”œâ”€â”€ Option 1: Role Based  âœ…
â”‚     â ask â€œWhich role?â€  
â”‚     â role_based_chain  
â”‚     â LLM  
â”‚     â return next interview question  
â”‚
â”œâ”€â”€ Option 2: JD Only  âœ…
â”‚     â upload JD text  
â”‚     â jd_based_chain
â”‚     â LLM  
â”‚     â tailored question  
â”‚
â”œâ”€â”€ Option 3: Resume Only   
â”‚     â upload resume text  
â”‚     â resume_based_chain  
â”‚     â LLM  
â”‚     â tailored question  
â”‚
â””â”€â”€ Option 4: Resume + JD  
      â upload JD text  
      â upload resume & JD text  
      â hybrid_chain (RAG + prompt)   
      â LLM question  
      â tailored question
```

## Folder Structure

```bash
ai_interviewer/
â”‚
â”œâ”€â”€ main.py                    # ğŸš€ Entry point: creates FastAPI app, includes all routers
â”œâ”€â”€ requirements.txt           # ğŸ“¦ Python dependencies
â”œâ”€â”€ .env                       # ğŸ” Env vars (e.g., API keys, model config)
â”‚
â”œâ”€â”€ app/                       # ğŸ§  Core application logic
â”‚   â”‚
â”‚   â”œâ”€â”€ chains/                # ğŸ’¬ LangChain chain definitions
â”‚   â”‚   â”œâ”€â”€ role_based_chain.py       # Defines ConversationChain for role-based chat
â”‚   â”‚   â””â”€â”€ jd_based_chain.py         # Defines ConversationChain for jd-based chat
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                # âš™ï¸ App-wide configuration
â”‚   â”‚   â””â”€â”€ settings.py               # Uses Pydantic `BaseSettings` to load env vars
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/                # ğŸ§  Session memory management
â”‚   â”‚   â”œâ”€â”€ role_conversation.py      # `ChatSession` class, `get_session()` logic
â”‚   â”‚   â””â”€â”€ jd_conversation.py        # `ChatSession` class, `get_session()` logic
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/               # ğŸ“ LLM prompt templates
â”‚   â”‚   â”œâ”€â”€ jd_evaluation_prompt.txt     # Prompt to generate the evaluation of jd based conversation
â”‚   â”‚   â”œâ”€â”€ jd_prompt.txt                # Prompt to generate the jd based conversation
â”‚   â”‚   â”œâ”€â”€ role_evaluation_prompt.txt   # Prompt to generate the evaluation of role based conversation
â”‚   â”‚   â””â”€â”€ role_prompt.txt              # Prompt to generate the role based conversation
â”‚   â”‚
â”‚   â”œâ”€â”€ routers/               # ğŸŒ FastAPI route handlers
â”‚   â”‚   â”œâ”€â”€ role_based.py              # /chat/role logic (handles role-based conversation)
â”‚   â”‚   â”œâ”€â”€ resume.py                  # /chat/resume (future expansion)
â”‚   â”‚   â”œâ”€â”€ jd.py                      # /chat/jd (based on JD input)
â”‚   â”‚   â”œâ”€â”€ hybrid.py                  # /chat/hybrid (resume + JD combo)
â”‚   â”‚   â””â”€â”€ status.py                  # /health or /status (heartbeat or version check)
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/              # ğŸ§¾ Pydantic models for validation
â”‚   â”‚   â”œâ”€â”€ role_based_schemas.py     # `ChatRequest`, `ChatResponse` for role mode
â”‚   â”‚   â””â”€â”€ jd_based_schemas.py       # `ChatRequest`, `ChatResponse` for role mode
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                 # ğŸ”§ Reusable utility modules
â”‚   â”‚   â””â”€â”€ logger.py                  # Centralized logger config
â”‚
â”‚
â”œâ”€â”€ data/                     # ğŸ“‚ Runtime storage
â”‚   â”œâ”€â”€ uploads/                      # Uploaded resumes or user files
â”‚   â”œâ”€â”€ logs/                         # Log output files (if written to disk)
â”‚   â””â”€â”€ vectorstore/                 # FAISS / pgvector / Chroma storage
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ streamlit_app.py      # ğŸ¨ User interface for the AI Interviewer
```